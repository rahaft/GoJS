{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahaft/GoJS/blob/master/DogVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqyZx2yTB0YI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd85f4f-783c-4e8a-eae6-7e7d54b397f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.19.0\n",
            "Hub version: 0.16.1\n",
            "GPU is available!!!!! \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "\n",
        "print(\"GPU is\", \"available!!!!! \" if tf.config.list_physical_devices(\"GPU\") else \"not available :-()\")\n",
        "\n",
        "#If GPU not avaialble go to Runtime > Change runtime time. Choose Python 3 > Hardware: one of the GPUs. Wait for Ram / Disk to change and rerun"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Data"
      ],
      "metadata": {
        "id": "QNSRhl9V5FHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzip files"
      ],
      "metadata": {
        "id": "Lb34cK4UAEbJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "fSqvN1XoFouD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e6c4d0-8a1d-43c9-c17b-17d32c1b9558"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/isic-2024-challenge/train-image.zip\n",
            "replace /content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-image/image/ISIC_0015670.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/drive/MyDrive/isic-2024-challenge/train-metadata.csv.zip\n",
            "replace /content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-metadata/train-metadata.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "#Unzip data if needed\n",
        "#!unzip \"/content/drive/MyDrive/ZeroToMastery/dog-breed-identification.zip\" -d \"/content/drive/MyDrive/ZeroToMastery/DogVision/\"\n",
        "\n",
        "#!mkdir -p \"/content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-image\"\n",
        "#!mkdir -p \"/content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-metadata\"\n",
        "\n",
        "#!unzip \"/content/drive/MyDrive/isic-2024-challenge/train-image.zip\" -d \"/content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-image/\"\n",
        "#!unzip \"/content/drive/MyDrive/isic-2024-challenge/train-metadata.csv.zip\" -d \"/content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-metadata/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## Set which data set we are working with\n",
        "\n",
        "* Set 1 - DogVision\n",
        "* Set 2 - ISCI - Lower quality images - https://www.kaggle.com/competitions/isic-2024-challenge/\n"
      ],
      "metadata": {
        "id": "GxRvpBHJn6wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_num = 2"
      ],
      "metadata": {
        "id": "vELpiUcnosRK"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if set_num == 1:\n",
        "  experiment_title = \"DogVision: \"\n",
        "elif set_num == 2:\n",
        "    experiment_title = \"ISCI: \"\n",
        "\n",
        "###########################\n",
        "\n",
        "image_type_num = 1\n",
        "split_index = .8  # To give 100% of your data to the training set, you set the validation portion to zero.\n",
        "\n",
        "NUM_IMAGES = 1000 #@param {type:\"slider\",min:1000,max:10000, step:1000} #SEt number of images to use for experimenting\n",
        "\n",
        "image_type = \"other\"  # will change direclty bleow this to pad, stretch, crop\n",
        "\n",
        "if image_type_num == 1:\n",
        "   # Maintains aspect ratio, fills gaps with black\n",
        "  image_type = \"pad\"\n",
        "elif image_type_num == 2:\n",
        "      # Forces image into square, can distort lesion shape\n",
        "    image_type =\"stretch\"\n",
        "\n",
        "elif image_type_num == 3:\n",
        "       # Resizes and crops to maintain aspect ratio without padding\n",
        "    image_type == \"crop\"\n"
      ],
      "metadata": {
        "id": "795igGkmcF3D"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting our data ready(turning it into Tensors)\n",
        "With all machine learning models, our data needs to be turned into numerical format. So that is what needs to be done first. This is turning our images into Tensors (numerical representations)\n",
        "\n",
        "###Step 1: Access data and check labels"
      ],
      "metadata": {
        "id": "VYThnxL0_vag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "DmJH1lIkFnRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d85f09e-f4ea-47e0-eacd-5c4621fdc1b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3133224938.py:8: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labels_csv = pd.read_csv(path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              target     age_approx  clin_size_long_diam_mm       tbp_lv_A  \\\n",
            "count  401059.000000  398261.000000           401059.000000  401059.000000   \n",
            "mean        0.000980      58.012986                3.930827      19.974007   \n",
            "std         0.031288      13.596165                1.743068       3.999489   \n",
            "min         0.000000       5.000000                1.000000      -2.487115   \n",
            "25%         0.000000      50.000000                2.840000      17.330821   \n",
            "50%         0.000000      60.000000                3.370000      19.801910   \n",
            "75%         0.000000      70.000000                4.380000      22.304628   \n",
            "max         1.000000      85.000000               28.400000      48.189610   \n",
            "\n",
            "         tbp_lv_Aext       tbp_lv_B    tbp_lv_Bext       tbp_lv_C  \\\n",
            "count  401059.000000  401059.000000  401059.000000  401059.000000   \n",
            "mean       14.919247      28.281706      26.913015      34.786341   \n",
            "std         3.529384       5.278676       4.482994       5.708469   \n",
            "min        -9.080269      -0.730989       9.237066       3.054228   \n",
            "25%        12.469740      24.704372      23.848125      31.003148   \n",
            "50%        14.713930      28.171570      26.701704      34.822580   \n",
            "75%        17.137175      31.637429      29.679913      38.430298   \n",
            "max        37.021680      54.306900      48.372700      58.765170   \n",
            "\n",
            "         tbp_lv_Cext       tbp_lv_H  ...  tbp_lv_radial_color_std_max  \\\n",
            "count  401059.000000  401059.000000  ...                401059.000000   \n",
            "mean       30.921279      54.653689  ...                     1.016459   \n",
            "std         4.829345       5.520849  ...                     0.734631   \n",
            "min        11.846520      -1.574164  ...                     0.000000   \n",
            "25%        27.658285      51.566273  ...                     0.563891   \n",
            "50%        30.804893      55.035632  ...                     0.902281   \n",
            "75%        33.963868      58.298184  ...                     1.334523   \n",
            "max        54.305290     105.875784  ...                    11.491140   \n",
            "\n",
            "         tbp_lv_stdL  tbp_lv_stdLExt  tbp_lv_symm_2axis  \\\n",
            "count  401059.000000   401059.000000      401059.000000   \n",
            "mean        2.715190        2.238605           0.306823   \n",
            "std         1.738165        0.623884           0.125038   \n",
            "min         0.268160        0.636247           0.052034   \n",
            "25%         1.456570        1.834745           0.211429   \n",
            "50%         2.186693        2.149758           0.282297   \n",
            "75%         3.474565        2.531443           0.382022   \n",
            "max        17.563650       25.534791           0.977055   \n",
            "\n",
            "       tbp_lv_symm_2axis_angle       tbp_lv_x       tbp_lv_y       tbp_lv_z  \\\n",
            "count            401059.000000  401059.000000  401059.000000  401059.000000   \n",
            "mean                 86.332073      -3.091862    1039.598221      55.823389   \n",
            "std                  52.559511     197.257995     409.819653      87.968245   \n",
            "min                   0.000000    -624.870728   -1052.134000    -291.890442   \n",
            "25%                  40.000000    -147.022125     746.519673      -8.962647   \n",
            "50%                  90.000000      -5.747253    1172.803000      67.957947   \n",
            "75%                 130.000000     140.474835    1342.131540     126.611567   \n",
            "max                 175.000000     614.471700    1887.766846     319.407000   \n",
            "\n",
            "       mel_thick_mm  tbp_lv_dnn_lesion_confidence  \n",
            "count     63.000000                  4.010590e+05  \n",
            "mean       0.670952                  9.716220e+01  \n",
            "std        0.792798                  8.995782e+00  \n",
            "min        0.200000                  1.261082e-16  \n",
            "25%        0.300000                  9.966882e+01  \n",
            "50%        0.400000                  9.999459e+01  \n",
            "75%        0.600000                  9.999996e+01  \n",
            "max        5.000000                  1.000000e+02  \n",
            "\n",
            "[8 rows x 37 columns]\n",
            "        isic_id  target  patient_id  age_approx   sex anatom_site_general  \\\n",
            "0  ISIC_0015670       0  IP_1235828        60.0  male     lower extremity   \n",
            "1  ISIC_0015845       0  IP_8170065        60.0  male           head/neck   \n",
            "2  ISIC_0015864       0  IP_6724798        60.0  male     posterior torso   \n",
            "3  ISIC_0015902       0  IP_4111386        65.0  male      anterior torso   \n",
            "4  ISIC_0024200       0  IP_8313778        55.0  male      anterior torso   \n",
            "\n",
            "   clin_size_long_diam_mm          image_type tbp_tile_type   tbp_lv_A  ...  \\\n",
            "0                    3.04  TBP tile: close-up     3D: white  20.244422  ...   \n",
            "1                    1.10  TBP tile: close-up     3D: white  31.712570  ...   \n",
            "2                    3.40  TBP tile: close-up        3D: XP  22.575830  ...   \n",
            "3                    3.22  TBP tile: close-up        3D: XP  14.242329  ...   \n",
            "4                    2.73  TBP tile: close-up     3D: white  24.725520  ...   \n",
            "\n",
            "    lesion_id  iddx_full  iddx_1  iddx_2  iddx_3  iddx_4  iddx_5  \\\n",
            "0         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
            "1  IL_6727506     Benign  Benign     NaN     NaN     NaN     NaN   \n",
            "2         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
            "3         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
            "4         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
            "\n",
            "   mel_mitotic_index  mel_thick_mm  tbp_lv_dnn_lesion_confidence  \n",
            "0                NaN           NaN                     97.517282  \n",
            "1                NaN           NaN                      3.141455  \n",
            "2                NaN           NaN                     99.804040  \n",
            "3                NaN           NaN                     99.989998  \n",
            "4                NaN           NaN                     70.442510  \n",
            "\n",
            "[5 rows x 55 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "if set_num == 1:\n",
        "  labels_csv = pd.read_csv(\"/content/drive/MyDrive/ZeroToMastery/DogVision/labels.csv\")\n",
        "elif set_num == 2:\n",
        "  path = \"/content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-metadata/train-metadata.csv\"\n",
        "\n",
        "labels_csv = pd.read_csv(path)\n",
        "\n",
        "############################\n",
        "\n",
        "print(labels_csv.describe())\n",
        "print(labels_csv.head())\n",
        "#alternative view\n",
        "#labels_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if set_num == 1:\n",
        "  # How many are there of each breed?\n",
        "  labels_csv[\"breed\"].value_counts()\n"
      ],
      "metadata": {
        "id": "rzGDRMKICJOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if set_num == 2:\n",
        "  # 1. Define the features we want to calculate based on ABCDE\n",
        "  columns = [\n",
        "    'isic_id',           # Unique identifier for the image\n",
        "    'asymmetry_score',   # A: 0 to 2 scale\n",
        "    'border_score',      # B: 0 to 8 scale\n",
        "    'color_count',       # C: Number of colors detected\n",
        "    'diameter_mm',       # D: Calculated from metadata\n",
        "    'target'             # The actual label (0=benign, 1=malignant)\n",
        "  ]\n",
        "\n",
        "  # 2. Create the empty DataFrame\n",
        "  abcde_results = pd.DataFrame(columns=columns)\n",
        "\n",
        "  # 3. (Optional) Pre-fill the isic_id and target from your main CSV\n",
        "  # This ensures your new table is perfectly aligned with your labels\n",
        "  abcde_results['isic_id'] = labels_csv['isic_id']\n",
        "  abcde_results['target'] = labels_csv['target']\n",
        "\n",
        "  # Display the first few rows of your new tracking table\n",
        "  print(\"Calculation Table Created:\")\n",
        "  print(abcde_results.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7e_fp_4vP1w",
        "outputId": "96056d3d-7e85-4f59-923f-20686d9170b2"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculation Table Created:\n",
            "        isic_id asymmetry_score border_score color_count diameter_mm  target\n",
            "0  ISIC_0015670             NaN          NaN         NaN         NaN       0\n",
            "1  ISIC_0015845             NaN          NaN         NaN         NaN       0\n",
            "2  ISIC_0015864             NaN          NaN         NaN         NaN       0\n",
            "3  ISIC_0015902             NaN          NaN         NaN         NaN       0\n",
            "4  ISIC_0024200             NaN          NaN         NaN         NaN       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check to see if we have the minimum number to train\n",
        "\n",
        "Ideally there are 100 annotations per labels. At least 10 is a good start."
      ],
      "metadata": {
        "id": "IQg54LWXKA_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if set_num == 1:\n",
        "  #float(labels_csv[\"breed\"].value_counts().mean())\n",
        "  avg_breed = labels_csv[\"breed\"].value_counts().mean()\n",
        "  print(f\"The average number of images per breed is: {avg_breed:.2f}\")\n",
        "\n",
        "  median_breed = labels_csv[\"breed\"].value_counts().median()\n",
        "  print(f\"The average number of images per breed is: {median_breed:.2f}\")\n",
        "elif set_num == 2:\n",
        "  avg_breed = labels_csv[\"iddx_1\"].value_counts().mean()\n",
        "  print(f\"The diagnoses is iddx_1: {avg_breed:.2f}\")\n",
        "\n",
        "  median_breed = labels_csv[\"iddx_1\"].value_counts().median()\n",
        "  print(f\"The average number of images per breed is: {median_breed:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mUkk4NRzItyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if set_num == 1:\n",
        "  labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10))\n",
        "elif set_num == 2:\n",
        "  labels_csv[\"iddx_1\"].value_counts().plot.bar(figsize=(20,10))"
      ],
      "metadata": {
        "id": "QrbtTZrTIkim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to view an image\n",
        "from IPython.display import Image\n",
        "Image(\"/content/drive/MyDrive/ZeroToMastery/DogVision/train/000bec180eb18c7604dcecc8fe0dba07.jpg\")"
      ],
      "metadata": {
        "id": "pWFTW2KwLBm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting images and their labels\n",
        "\n",
        "Let's get a list of all our image files"
      ],
      "metadata": {
        "id": "ukcheavvL86F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "euRD8hMlOFsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pathname from image IDs\n",
        "if set_num == 1:\n",
        "  filename= [\"/content/drive/MyDrive/ZeroToMastery/DogVision/train/\" + fname +\".jpg\" for fname in labels_csv[\"id\"]]\n",
        "  # Check the first one\n",
        "  filename[0]\n",
        "elif set_num == 2:\n",
        "  filename= [\"/content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-image/\" + fname +\".jpg\" for fname in labels_csv[\"id\"]]\n",
        "  # Check the first one\n",
        "  filename[0]\n"
      ],
      "metadata": {
        "id": "Mk_SdD31Mbom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename0= [fname for fname in labels_csv[\"id\"]]\n",
        "filename0[0]"
      ],
      "metadata": {
        "id": "ZoPAJcWBMbLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether number of filenames matches number of actual images\n",
        "import os\n",
        "\n",
        "if set_num == 1:\n",
        "  if len(os.listdir(\"/content/drive/MyDrive/ZeroToMastery/DogVision/train\"))==len(filename):\n",
        "    print(\"Filenames match actual image count\")\n",
        "  else:\n",
        "    print(\"Filenames do not match actual image count\")\n",
        "elif set_num == 2:\n",
        "  if len(os.listdir(\"/content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-image\"))==len(filename):\n",
        "    print(\"Filenames match actual image count\")\n",
        "  else:\n",
        "    print(\"Filenames do not match actual image count\")"
      ],
      "metadata": {
        "id": "cRZ8fyYrSRwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check random image to make sure working\n",
        "import random\n",
        "\n",
        "# Generate a random index between 0 and the end of your filename list\n",
        "random_index = random.randint(0, len(filename0) - 1)\n",
        "\n",
        "print(random_index)\n",
        "\n",
        "if set_num == 1:\n",
        "  labels_csv[\"id\"][random_index]\n",
        "elif set_num == 2:\n",
        "  labels_csv[\"isic_id\"][random_index]\n",
        "print(f\"Path 1: {filename[random_index]}\")\n",
        "print(f\"Path 2: {filename0[random_index]}\")\n",
        "\n",
        "if set_num == 1:\n",
        "  print(f\"Breed: {labels_csv[\"breed\"][random_index]}\")\n",
        "elif set_num == 2:\n",
        "   print(f\"Diagnosis: {labels_csv[\"iddx_1\"][random_index]}\")\n",
        "#filename0[random_index]\n",
        "Image(filename[random_index])"
      ],
      "metadata": {
        "id": "TtqDNVNtSMYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning Data Labels Into Numbers"
      ],
      "metadata": {
        "id": "fCFXukf5ebDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have our training image filepaths and now we needlabels\n",
        "if set_num == 1:\n",
        "  labels = labels_csv[\"breed\"]\n",
        "elif set_num == 2:\n",
        "  labels = labels_csv[\"iddx_1\"]\n",
        "\n",
        "labels = np.array(labels)\n",
        "print(f\"Length of labels: {len(labels)}\")\n",
        "print(f\"Labels: {(labels)}\")\n",
        "\n",
        "if len(labels) == len(filename):\n",
        "  print(\"Number of labels matches number of filenames!\")\n",
        "else:\n",
        "  print(\"Number of labels does not match number of filenames, check data directories\")"
      ],
      "metadata": {
        "id": "uuuB_H7feuNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_breeds = np.unique(labels)\n",
        "print(f\"Number of unique breeds: {len(unique_breeds)}\")\n",
        "print(f\"\")\n",
        "print(f\"Unique breeds: {(unique_breeds)}\")\n"
      ],
      "metadata": {
        "id": "Xl0mj0rOgyF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn single label into an array of booleans where everywhere there is a unique breeds but where it does equal it is true\n",
        "print(labels[0])\n",
        "labels[0] == unique_breeds"
      ],
      "metadata": {
        "id": "rfkAgHPqhKAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn every label into a boolean array\n",
        "#boolean_labels = [label == np.array(unique_breeds) for label in labels]\n",
        "boolean_labels = [label == unique_breeds for label in labels]\n",
        "boolean_labels[:2]\n"
      ],
      "metadata": {
        "id": "Ngt8kTEjhj4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(boolean_labels)"
      ],
      "metadata": {
        "id": "yxkrVCuUh_BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exaample Turning boolean array into integers\n",
        "print(labels[0]) # Original label\n",
        "print(np.where(unique_breeds==labels[0]))  #index where label occurs\n",
        "print(boolean_labels[0].argmax()) #index where label occurs in boolean array\n",
        "print(boolean_labels[0].astype(int)) # There will be a 1 where the sample label occurs"
      ],
      "metadata": {
        "id": "pMt5vZf1iBOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example Turning boolean array into integers\n",
        "var_index = 2\n",
        "VI = var_index\n",
        "print(labels[var_index]) # Original label\n",
        "print(np.where(unique_breeds==labels[var_index]))  #index where label occurs\n",
        "print(boolean_labels[var_index].argmax()) #index where label occurs in boolean array\n",
        "print(boolean_labels[var_index].astype(int)) # There will be a 1 where the sample label occurs"
      ],
      "metadata": {
        "id": "7fZXAtt0ij9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating our own validation set\n",
        "Since the dataset from kaggle doesn't come with a validation set so we will make our own\n",
        "\n",
        "We wills tart with ~1000 images and increase as needed"
      ],
      "metadata": {
        "id": "uln5xvxUiz82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up x and y variables\n",
        "X = filename\n",
        "y = boolean_labels"
      ],
      "metadata": {
        "id": "7n7cSJliixD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPx9iW5hjL6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's split data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "NUM_IMAGES = int(split_index * NUM_IMAGES)\n",
        "\n",
        "#Split them into training and validation of total size Num_images\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],y[:NUM_IMAGES],test_size=(1-split_index),random_state=42)\n",
        "\n",
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "metadata": {
        "id": "OtAwxNd7jlht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's have a loook at the training data\n",
        "X_train[:5], y_train[:2]"
      ],
      "metadata": {
        "id": "kVrg1IZ2kYAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Images\n",
        "\n",
        "Turning images into tensors (numerical representation)\n",
        "\n",
        "To preprocess images into tensors. We will write a function that does a few things:\n",
        "1. Take an image filapath as input\n",
        "2. Use Tensorflow to read the file and save it to a variable 'image'\n",
        "3. Turn our 'image' (a jpeg) into Tensors\n",
        "4. Resize the image to be the shape of (224,224)\n",
        "5. Return modified image\n",
        "\n",
        "Tutorials on\n",
        "[Tensorflow.org/tutorials ](https://Tensorflow.org/tutorials )\n",
        "\n",
        "How to load images [Tensorflow.org/tutorials/load_data/images ](https://Tensorflow.org/tutorials/load_data/images)"
      ],
      "metadata": {
        "id": "dPhjNPaKkk4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert image to NumPy array\n",
        "from matplotlib.pyplot import imread\n",
        "var_index = 42\n",
        "VI = var_index\n",
        "image = imread(filename[VI])\n",
        "print(f\"\" )\n",
        "print(f\"Image Shape: {(image.shape)}\")\n",
        "print(f\"Image Max: {(image.max())}\")\n",
        "print(f\"Image Min: {(image.min())}\")"
      ],
      "metadata": {
        "id": "ha5bzUTsk0og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "3zyuOOOMmSOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image[:2]"
      ],
      "metadata": {
        "id": "IosdDp5bm58o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can create a tensor from any image using\n",
        "tf.constant(image)[:2]"
      ],
      "metadata": {
        "id": "3SU66RowkhIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--\n",
        "## Input functions"
      ],
      "metadata": {
        "id": "Le-X0ABicBww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Images pt 2\n",
        "Now we've seen what an image looks like as a Tensor, let's make a function to preprocess them\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   Take an image filapath as input\n",
        "2.   Use Tensorflow to read the file and save it to a variable 'image'\n",
        "3. Turn our 'image' (a jpeg) into Tensors\n",
        "4. Resize the image to be the shape of (224,224)\n",
        "5. Return modified image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "23KMmru2nHXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define image size (Using a single integer for height/width)\n",
        "IMG_SIZE = 224\n",
        "\n",
        "def process_image(image_path, image_type_num, img_size=IMG_SIZE):\n",
        "    \"\"\"\n",
        "    Takes an image file path and turns it into a Tensor.\n",
        "    Handles decoding, normalization, and resizing with padding.\n",
        "    \"\"\"\n",
        "\n",
        "    method = image_type_num\n",
        "    # 1. Read in the image file\n",
        "    raw_file = tf.io.read_file(image_path)\n",
        "\n",
        "    # 2. Decode the image.\n",
        "    # channels=3 ensures we get RGB even if the original is grayscale or RGBA.\n",
        "    image = tf.image.decode_jpeg(raw_file, channels=3)\n",
        "\n",
        "    # 3. Convert the color channel values from 0-255 to 0-1 (float32)\n",
        "    # This also acts as your normalization step\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "    # 4. Resize the image\n",
        "    # resize_with_pad adds black borders to maintain aspect ratio without stretching\n",
        "    image = tf.image.resize_with_pad(image,\n",
        "                                     target_height=img_size,\n",
        "                                     target_width=img_size)\n",
        "\n",
        "    if method == 1:\n",
        "        # Maintains aspect ratio, fills gaps with black\n",
        "        image = tf.image.resize_with_pad(image, img_size, img_size)\n",
        "\n",
        "    elif method == 2:\n",
        "        # Forces image into square, can distort lesion shape\n",
        "        image = tf.image.resize(image, [img_size, img_size])\n",
        "\n",
        "    elif method == 3:\n",
        "        # Resizes and crops to maintain aspect ratio without padding\n",
        "        image = tf.image.resize_with_crop_or_pad(image, img_size, img_size)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "CEZ0J_U3nM4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Note: It is better to center the image instead of stretching or cropping arbitrarily"
      ],
      "metadata": {
        "id": "TyfqfrI1sHTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test what is happening at each stage\n",
        "#tensor = tf.io.read_file(filename[26])\n",
        "#tensor = tf.image.decode_jpeg(tensor,channels=3)\n",
        "#tensor =tf.image.convert_image_dtype(tensor, tf.float32)\n",
        "\n",
        "#tensor"
      ],
      "metadata": {
        "id": "MeiNAGUrnx2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning Data into Batches\n",
        "\n",
        "32 is default batchsize  \n",
        "\n",
        "Resources:\n",
        "Yann lecun\n",
        "Jeremy howard\n",
        "\n",
        "Why? If we try to calculate patterns in all 10000 images in one go they might not all fit into memory -- GPU is fast but still has limited memory. It might be more than 8 gb.\n",
        "\n",
        "You can manually adjust batch size if necessary\n",
        "\n",
        "To use TensorFlow effectively, we need our daa in the form of Tensor tuples which look like this\n",
        "'(image, label)'"
      ],
      "metadata": {
        "id": "-8NwnKaGr_w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple function to return a tuple (image, label)\n",
        "def get_image_label(image_path,label):\n",
        "  \"\"\" takes an image file path name and the associated label processes the image and returns a tuple of image, label \"\"\"\n",
        "  image = process_image(image_path,image_type_num)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "0YMNWYvWsCPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#demo of the above\n",
        "#(process_image(X[42]),y[42])\n",
        "(process_image(X[42],image_type_num),tf.constant(y[42]))"
      ],
      "metadata": {
        "id": "WNrLh3NltnfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turn Data into Batches 2\n",
        "\n",
        "Now we have a way to turn data into tuples of Tensors in the form (image,label) lets make a function to turn all of our data (X and y) into batches\n",
        "\n",
        "Read through documentation"
      ],
      "metadata": {
        "id": "p12BIPgpuNVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size 32 is a good start\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create a function to turn data into batches\n",
        "def create_data_batches(X,y=None, batch_size = BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image (X) and label (y) pairs.\n",
        "  Shuffles the data if its training data but doesn't shffle if it is validation data\n",
        "  Also accepts test data as input (no labels)\n",
        "  \"\"\"\n",
        "\n",
        "  # If the data is a test data set we don't have the labels\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths no labels\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  # If the data is a valid dataset we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), #filepaths\n",
        "                                               tf.constant(y))) #labels\n",
        "\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    print(\"Creating training data batches...\")\n",
        "    # Turn filepaths and labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
        "\n",
        "    # Shuffling pathnames and labels...\n",
        "    data = data.shuffle(buffer_size=len(X))\n",
        "\n",
        "    #Create image label tuples which turns image path into preprocessed image\n",
        "    data = data.map(get_image_label)\n",
        "\n",
        "    #Turn training data into batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "    return data_batch"
      ],
      "metadata": {
        "id": "CMHjtxnWuV3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and data validation data batches\n",
        "\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "val_data = create_data_batches(X_val, y_val, valid_data=True)"
      ],
      "metadata": {
        "id": "-a737p1Fws5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the different attrivutes of data athes\n",
        "train_data.element_spec,val_data.element_spec"
      ],
      "metadata": {
        "id": "jeXcdlvvw4Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Our Data\n",
        "\n",
        "Our data is now in batches but it's abstract.\n",
        "\n",
        "Visualizations below"
      ],
      "metadata": {
        "id": "WUuIRpdQxMZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualizing data batches\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function for viewing images in a databatch\n",
        "def show_25_images (images,labels):\n",
        "  \"\"\"\n",
        "  Displays a plot of 25 images and their labels from data batch\n",
        "  \"\"\"\n",
        "  # Set up the figure\n",
        "  plt.figure(figsize=(10,10))\n",
        "  #Loop through 25 for displaying 25 images\n",
        "  for i in range(25):\n",
        "    ax = plt.subplot(5,5,i+1)\n",
        "    #Display an image\n",
        "    plt.imshow(images[i])\n",
        "    #Add the image label as the title\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    #Turn the grid lines off\n",
        "    #plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "YVUHJYf_xYcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "hw8XisD0yVIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "train_images, train_labels\n",
        "#show_25_images"
      ],
      "metadata": {
        "id": "sVshC3B2yKRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images), len(train_labels)"
      ],
      "metadata": {
        "id": "GkDSno8Rzysc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's visualize in our training batch\n",
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "show_25_images(train_images,train_labels)"
      ],
      "metadata": {
        "id": "oXPm3Lb3z7dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's visaulize our validation set\n",
        "val_images, val_labels = next(val_data.as_numpy_iterator())\n",
        "show_25_images(val_images,val_labels)"
      ],
      "metadata": {
        "id": "sfxqyhnB0wFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Our Inputs and Outputs\n",
        "\n",
        "Before building model there are lots of ways to build models\n",
        "\n",
        "We can take existing model\n",
        "Once we have baseline results\n",
        "Few things we need to define\n",
        "* The input shape (our images shape in the form of tensors) to our model\n",
        "* The output shape (image labels in the form of tensors) of our model\n",
        "* The URL of the model we want to use"
      ],
      "metadata": {
        "id": "j0cJNnKsxTEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a model -- input shape and output shape and URL of model\n",
        "IMG_SIZE"
      ],
      "metadata": {
        "id": "SBncIwS7xSpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup the input shape to the model\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE,3]\n",
        "\n",
        "# Setup output shape of our model\n",
        "OUTPUT_SHAPE = len(unique_breeds)\n",
        "\n",
        "# Setup model URL from Tensorflow Hub\n",
        "# MODEL_URL =\n"
      ],
      "metadata": {
        "id": "6gQlzAEtxK88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How machines learn and waht's going on behind the scenes\n",
        "\n",
        "How machines learn by GCP Grey on [Youtube](https://youtube.com/watch?v=R9OHn5ZF4Uo)\n",
        "\n",
        "Deep Learning series by 3Blue1Brown on [Youtube](https://youtube.com/watch?v=aircAruvnKk)"
      ],
      "metadata": {
        "id": "sovTmGXn18He"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Deep Learning Model\n",
        "TensorFlow Hub is a library for reusable machine learning modules\n",
        "Makes it very easy to get started.\n",
        "Model Zoo\n",
        "Papers with code\n",
        "Pytorch\n",
        "Pytorch at tesla\n",
        "\n",
        "Tensor flow hub\n",
        "-- Search by problem domain\n",
        "-- Similar to scikit\n",
        "-- Architecture can be neural network\n",
        "----Resent -- click on it -- Copy to clipboard -- download model create a resnet model\n",
        "Resnet 50 dialated backbones\n",
        "Resnet [https://youtu.be/oBklltKXtDE?t=173](https://youtu.be/oBklltKXtDE)\n",
        "\n",
        "The higher the number the better and logner to train\n",
        "\n",
        "Mobilenet v2\n",
        "- Requires Tensorflow 2\n"
      ],
      "metadata": {
        "id": "YIJ4lMDS4dHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup the input shape to the model\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE,3]\n",
        "\n",
        "# Setup output shape of our model\n",
        "OUTPUT_SHAPE = len(unique_breeds)\n",
        "\n",
        "# Setup model URL from Tensorflow Hub\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\"\n"
      ],
      "metadata": {
        "id": "a-T7WwCu48Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Deep Learning Model pt 2\n",
        "\n",
        "Use tensor flow keras api\n",
        "\n",
        "High level api for deep learning\n",
        "User friendly\n",
        "Easy to extend\n",
        "Modular\n",
        "\n",
        "Keep in mind difference between sequential and functional (currently using sequential)\n",
        "\n",
        "Neural layers --\n",
        "- input\n",
        "-- other layers to find patterns\n",
        "--- output\n",
        "\n",
        "\n",
        " Now we have inputs outputs and model -- let's put into kearas deep learning module\n",
        "  Creating a function which takes the input shape, output shape and model chosen as peramiters\n",
        "Define layers in Keras model in sequential -- do this first and then that\n",
        " Compiles model says what it should be evaluated and improved\n",
        " Builds the model - tels the model and the input shape\n",
        " Returns the model\n",
        "\n",
        "tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4  >>  m.build ([None,224,224,3])"
      ],
      "metadata": {
        "id": "190-sfBi6nsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function which builds a Keras model\n",
        "## Not currently working\n",
        "## compatible with old verison\n",
        "def create_model_v1(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE,model_url=MODEL_URL):\n",
        "  print(\"Building model with:\", MODEL_URL)\n",
        "\n",
        "  #Setup the model layers\n",
        "  model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
        "    tf.keras.layers.Dense(units=OUTPUT_SHAPE, activation=\"softmax\") # Layer 2 (output layer)\n",
        "  ])\n",
        "\n",
        "  # Complie the model\n",
        "  model.complie(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE)\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "9RSP6-G36mt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
        "    print(\"Building model with Keras Applications (MobileNetV2)\")\n",
        "\n",
        "    # 1. Setup the base model from Keras instead of TF Hub\n",
        "    # We use include_top=False to remove the 1000-class ImageNet head\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "\n",
        "    # 2. Freeze the base model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # 3. Create your custom model\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(), # Flattens the base model output\n",
        "        tf.keras.layers.Dense(units=output_shape, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    # 4. Compile the model\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "NlZ4mYXhLs64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Currently working  compatible with old version\n",
        "import tensorflow as tf\n",
        "## v1 used this but want to get rid of it\n",
        "#import tensorflow_hub as hub\n",
        "import tf_keras  # Import the compatibility wrapper\n",
        "\n",
        "# Update your URL to the new Kaggle format (or use the redirect)\n",
        "# MODEL_URL = \"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/1\"\n",
        "\n",
        "def create_model_v1():\n",
        "    # Use tf_keras.Sequential instead of tf.keras.Sequential\n",
        "    model = tf_keras.Sequential([\n",
        "        hub.KerasLayer(MODEL_URL, input_shape=(224, 224, 3)),\n",
        "        tf_keras.layers.Dense(len(unique_breeds), activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "J_J5_DZv-WPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compatible with this version\n",
        "import tensorflow as tf\n",
        "\n",
        "# Update your URL to the new Kaggle format (or use the redirect)\n",
        "MODEL_URL = \"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/1\"\n",
        "\n",
        "def create_model():\n",
        "    # 1. Use the built-in MobileNetV2 from tf.keras (No tf_keras or hub needed)\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(224, 224, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "\n",
        "    # 2. Freeze the base model\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # 3. Use tf.keras.Sequential (NOT tf_keras)\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(), # Flattens the 4D output to 1D\n",
        "        tf.keras.layers.Dense(len(unique_breeds), activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "VIcSLoJtMw2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Nlab2pjJ8Tfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Deep Learning Model 3\n",
        "\n",
        "Linear stack of layers -- Find patterns in input and create some output\n",
        "\n",
        "Why do they have two layers\n",
        "\n",
        "towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-84...\n",
        "\n",
        "Check out CNN\n",
        "\n",
        "Transfer learning -- a lot is re==predone\n",
        "\n",
        "Check out softmax -- each component will be interval 0,1\n",
        "Binary -- signoid\n",
        "\n",
        "Natural output is 1280 -- but we only need 120\n"
      ],
      "metadata": {
        "id": "tEd9Aa0t-6Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = np.ones(shape=(1,1, 1280))\n",
        "outputs\n"
      ],
      "metadata": {
        "id": "uJyTankH92lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizing our model\n",
        "\n",
        "### and editing\n",
        " Loss is height of the hill. Wants to get to 0.\n",
        " When it's learning the training set to compare image to a label\n",
        " Higher the loss the worse the prediction\n",
        " Higher we are -- goal is to get to bottom of the hill\n",
        "\n",
        " Adam is telling how to get to bottom of the hill - can see movemenet sand instructions\n",
        "\n",
        " Adam is an optimizer that works well on most models\n",
        " Metrics is how well doing at the bottom of the hill\n",
        " How well predicting label\n",
        "\n",
        " Search: How to choose a loss function in machine learning models\n",
        "\n",
        " ---- How to choose loss function\n",
        "\n",
        " Binary classification --- if something is one or another -- cat or dog\n",
        " Change activation: Sigmoid\n",
        " Loss function to binary cross entroppy\n",
        "\n",
        " Multiclass\n",
        " - Activation is softmax\n",
        " Loss- Categorical\n",
        "\n",
        " so loss - tf.keras.losses.CategoricalCrossentropy\n",
        "\n",
        " Metrics -- can use different metrics (search tf keras metrics)\n",
        "\n",
        " Use accuracy for classification\n",
        "\n",
        " Area under the curve, categorial, mean, precision, recall, etc.\n",
        "\n",
        "[ tensorflow.org/api_docs/python/tf/keras/metrics](https://tensorflow.org/api_docs/python/tf/keras/metrics)\n",
        "\n",
        "\n",
        "Building\n",
        "\n",
        "Just another way to say this is the input shape taking to the model -- taking from tensor flow hub -- if we want touse the layer set up a sequential model\n",
        "keras.Sequential\n",
        "m.build(none,224,224,3) -- size of images that mobilenet is trained on\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_oGFn1HVAJbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizing Our Model\n",
        "\n",
        "Layer\n",
        "\n",
        "Non trainable lines up with param\n",
        "\n",
        "Dense with param number 120k that corresponds to dense layer\n",
        "\n",
        "Non-trainable params -- using mobile net v2\n",
        "\n",
        "There are specific patterns mobilenet has learned.\n",
        "\n",
        "What images did mobile net go through\n",
        "\n",
        "Search for imagenet -- weights were obtained by training on ILSVRC-2012-CLS imagenet\n",
        "imagenet organized according to wordnet hierarchy\n",
        "500 images per node\n",
        "\n",
        "Image net is large database of over 14 million images\n",
        "Patterns are what mobile net has learned by training on image net\n",
        "\n",
        "Transfer learning -- all patterns leraned each layer is a layer in the neural network\n",
        "\n",
        "-----\n",
        "\n",
        "5 1/2 Found\n",
        "\n",
        "Utilize patterns found in own pattern\n",
        "\n",
        "Find from scratch -- hours and lots of compute power -- utilize and train our own 120k parameters\n",
        "\n",
        "Dense layer\n",
        "\n",
        "Classify which dogbreed is in which photo\n",
        "\n",
        "Create callbacks\n",
        "\n",
        "Create a function"
      ],
      "metadata": {
        "id": "JSiFXRhVCfuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Our Model\n",
        "\n",
        "Checked out what summarizing means\n",
        "\n",
        "Call backs\n",
        "\n",
        "### Creating callbascks\n",
        "\n",
        "Callbacks are helper functions a model can use during training to do such things as save its progress, check its progress to stop training early if model stops improving\n",
        "\n",
        "Why should we implement\n",
        "\n",
        "tensorflow.keras.model callbacks -- check documentation\n",
        "tensorflow.org/guide/keras/custom_callbacks\n",
        "\n",
        "Can train model for up to a week at a time.\n",
        "\n",
        "Want to know how its going and what it's doing.\n",
        "\n",
        "Want to stop early before it overfits.\n",
        "\n",
        "Will do callbacks in action\n",
        "\n",
        "Create two callbacks\n",
        "\n",
        "One for Tensorboard which helps track our model progress and another for early stopping which prevents our model from training for too long\n",
        "\n",
        "\n",
        "### TensorBoard callback\n",
        "tensorflow.org/\n",
        "\n",
        "#### To set up Tensorboard callback we need 3 things\n",
        "1. Load the Tensorboard notebook extension\n",
        "2. Create a Tensorboard callback which is able to save logs to a directory -- how it's doing during trianng and pass to model's fit() function\n",
        "3. Visualize our models training logs with the '%tensorboard machic function' -- do this after model training  "
      ],
      "metadata": {
        "id": "RSIqASSWDmXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load TensorBoard notebook extension\n",
        "%load_ext tensorboard\n"
      ],
      "metadata": {
        "id": "J_PiSsVmDrCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback --start timelog\n",
        "import datetime\n",
        "def create_tensorboard_callback():\n",
        "  # Fix the typo: 'dateime' -> 'datetime'\n",
        "  logdir = os.path.join(\"/content/drive/MyDrive/ZeroToMastery/DogVision/logs\",\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "  # Ensure you are using tf.keras specifically to avoid attribute errors\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "metadata": {
        "id": "4fnzF0xWEh3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preventing Overfitting\n",
        "\n",
        "Create an early stopping callback\n",
        "\n",
        "Tensorflow kears early stopping callback\n",
        "\n",
        "Early stopping helps our model from overfitting by stopping trainng if a certain evaluation metric stops improving."
      ],
      "metadata": {
        "id": "R8z2U-f-GMXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create aerly stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=3)\n",
        "\n",
        "#Patience 3 is the number of epochs with the value"
      ],
      "metadata": {
        "id": "x4nGcfnTG0yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training your deep neural network\n",
        "### On a subset of data -- 1000 images\n",
        "\n",
        "Why? To make sure everything is working\n",
        "\n",
        "One more variable to define -- number of epochs -- how many passes of data we'd like data to do\n",
        "\n",
        "Equivalent to model finding patterns in\n",
        "\n",
        "As it learns patterns -- will guess --\n",
        "\n",
        "Tell model how it will guess with each epoch\n",
        "\n",
        "Tell how it is going on accuracy\n",
        "\n",
        "Watching how well performing"
      ],
      "metadata": {
        "id": "nKxa6w13HTRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}"
      ],
      "metadata": {
        "id": "2U_mVnP5HKcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Double check we are using a GPU\n",
        "print(\"GPU\",\"available? YESSSSS \" if tf.config.list_physical_devices(\"GPU\") else \"not available :-(\")"
      ],
      "metadata": {
        "id": "lZ0zfEkxIGLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ------\n",
        "Let's create a function which trains a model\n",
        " * create a model using 'create model\n",
        " * Set up a tensorBoard Callback using create_tensor_board_callback()\n",
        "\n",
        "* Call the 'fit()' funciton on model passing the training data and validation data\n",
        "number of epocs tho train for (NUM_EPOCHS)\n",
        "and the callback swhich are the helper functions\n",
        "* Return the model"
      ],
      "metadata": {
        "id": "ju_YnwX4IYT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a function to train and return a trained model\n",
        "def train_model(experiment_title, split_index, NUM_IMAGES , image_type ):\n",
        "  \"\"\"\n",
        "  Trains a given model and returns the trained version\n",
        "  \"\"\"\n",
        "\n",
        "  print(\"=\"*40)\n",
        "  print(f\"EXPERIMENT: {experiment_title}\")\n",
        "  print(f\"IMAGE TYPE: {image_type}\")\n",
        "  print(f\"SPLIT RATIO: {1-split_index:.1f} Train / {split_index:.1f} Val\")\n",
        "  print(f\"TOTAL IMAGES: {NUM_IMAGES}\")\n",
        "  print(\"=\"*40)\n",
        "\n",
        "  # Create a model\n",
        "  model = create_model()\n",
        "\n",
        "  # Create new TensorBoard session everytime we train a model\n",
        "  tensorboard = create_tensorboard_callback()\n",
        "\n",
        "  # Fit the model to the data passing it the callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            validation_data=val_data,\n",
        "            validation_freq = 1,\n",
        "            callbacks = [tensorboard,early_stopping])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "LUf9VDcPIrJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIt the model to the data\n",
        "model = train_model(experiment_title, split_index, NUM_IMAGES , image_type )"
      ],
      "metadata": {
        "id": "3wgZsNf0JdTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/drive/MyDrive/ZeroToMastery/DogVision/logs"
      ],
      "metadata": {
        "id": "0dqYnSPBfAKM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "https://github.com/rahaft/GoJS/blob/master/DogVision.ipynb",
      "authorship_tag": "ABX9TyPsZYiG3a+Jj+yDcGFOJxgb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}