{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahaft/GoJS/blob/master/DogVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YqyZx2yTB0YI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d4da82-8ede-42ca-fbec-fe2474950a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.19.0\n",
            "Hub version: 0.16.1\n",
            "GPU is available!!!!! \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "\n",
        "print(\"GPU is\", \"available!!!!! \" if tf.config.list_physical_devices(\"GPU\") else \"not available :-()\")\n",
        "\n",
        "#If GPU not avaialble go to Runtime > Change runtime time. Choose Python 3 > Hardware: one of the GPUs. Wait for Ram / Disk to change and rerun"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Data"
      ],
      "metadata": {
        "id": "QNSRhl9V5FHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzip files"
      ],
      "metadata": {
        "id": "Lb34cK4UAEbJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fSqvN1XoFouD"
      },
      "outputs": [],
      "source": [
        "#Unzip data if needed\n",
        "#!unzip \"/content/drive/MyDrive/ZeroToMastery/dog-breed-identification.zip\" -d \"/content/drive/MyDrive/ZeroToMastery/DogVision/\"\n",
        "\n",
        "#!unzip \"/content/drive/MyDrive/isic-2024-challenge/train-image.zip\" -d \"/content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-image/\"\n",
        "#!unzip \"/content/drive/MyDrive/isic-2024-challenge/train-metadata.csv.zip\" -d \"/content/drive/MyDrive/ZeroToMastery/ISCI-2024-Challenge/train-metadata/\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting our data ready(turning it into Tensors)\n",
        "With all machine learning models, our data needs to be turned into numerical format. So that is what needs to be done first. This is turning our images into Tensors (numerical representations)\n",
        "\n",
        "###Step 1: Access data and check labels"
      ],
      "metadata": {
        "id": "VYThnxL0_vag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DmJH1lIkFnRw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "19936f28-a170-495f-c566-36ca70867670"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ZeroToMastery/DogVision/labels.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3228486564.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/ZeroToMastery/DogVision/labels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#alternative view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#labels_csv.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ZeroToMastery/DogVision/labels.csv'"
          ]
        }
      ],
      "source": [
        "labels_csv = pd.read_csv(\"/content/drive/MyDrive/ZeroToMastery/DogVision/labels.csv\")\n",
        "print(labels_csv.describe())\n",
        "print(labels_csv.head())\n",
        "#alternative view\n",
        "#labels_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many are there of each breed?\n",
        "labels_csv[\"breed\"].value_counts()"
      ],
      "metadata": {
        "id": "rzGDRMKICJOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check to see if we have the minimum number to train\n",
        "\n",
        "Ideally there are 100 annotations per labels. At least 10 is a good start."
      ],
      "metadata": {
        "id": "IQg54LWXKA_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#float(labels_csv[\"breed\"].value_counts().mean())\n",
        "avg_breed = labels_csv[\"breed\"].value_counts().mean()\n",
        "print(f\"The average number of images per breed is: {avg_breed:.2f}\")\n",
        "\n",
        "median_breed = labels_csv[\"breed\"].value_counts().median()\n",
        "print(f\"The average number of images per breed is: {median_breed:.2f}\")"
      ],
      "metadata": {
        "id": "mUkk4NRzItyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10))"
      ],
      "metadata": {
        "id": "QrbtTZrTIkim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to view an image\n",
        "from IPython.display import Image\n",
        "Image(\"/content/drive/MyDrive/ZeroToMastery/DogVision/train/000bec180eb18c7604dcecc8fe0dba07.jpg\")"
      ],
      "metadata": {
        "id": "pWFTW2KwLBm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting images and their labels\n",
        "\n",
        "Let's get a list of all our image files"
      ],
      "metadata": {
        "id": "ukcheavvL86F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "euRD8hMlOFsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pathname from image IDs\n",
        "filename= [\"/content/drive/MyDrive/ZeroToMastery/DogVision/train/\" + fname +\".jpg\" for fname in labels_csv[\"id\"]]\n",
        "\n",
        "# Check the first one\n",
        "filename[0]"
      ],
      "metadata": {
        "id": "Mk_SdD31Mbom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename0= [fname for fname in labels_csv[\"id\"]]\n",
        "filename0[0]"
      ],
      "metadata": {
        "id": "ZoPAJcWBMbLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether number of filenames matches number of actual images\n",
        "import os\n",
        "if len(os.listdir(\"/content/drive/MyDrive/ZeroToMastery/DogVision/train\"))==len(filename):\n",
        "  print(\"Filenames match actual image count\")\n",
        "else:\n",
        "  print(\"Filenames do not match actual image count\")"
      ],
      "metadata": {
        "id": "cRZ8fyYrSRwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check random image to make sure working\n",
        "\n",
        "import random\n",
        "\n",
        "# Generate a random index between 0 and the end of your filename list\n",
        "random_index = random.randint(0, len(filename0) - 1)\n",
        "\n",
        "print(random_index)\n",
        "\n",
        "labels_csv[\"id\"][random_index]\n",
        "print(f\"Path 1: {filename[random_index]}\")\n",
        "print(f\"Path 2: {filename0[random_index]}\")\n",
        "print(f\"Breed: {labels_csv[\"breed\"][random_index]}\")\n",
        "#filename0[random_index]\n",
        "Image(filename[random_index])"
      ],
      "metadata": {
        "id": "TtqDNVNtSMYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning Data Labels Into Numbers"
      ],
      "metadata": {
        "id": "fCFXukf5ebDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have our training image filepaths and now we needlabels\n",
        "labels = labels_csv[\"breed\"]\n",
        "labels = np.array(labels)\n",
        "print(f\"Length of labels: {len(labels)}\")\n",
        "print(f\"Labels: {(labels)}\")\n",
        "\n",
        "if len(labels) == len(filename):\n",
        "  print(\"Number of labels matches number of filenames!\")\n",
        "else:\n",
        "  print(\"Number of labels does not match number of filenames, check data directories\")"
      ],
      "metadata": {
        "id": "uuuB_H7feuNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_breeds = np.unique(labels)\n",
        "print(f\"Number of unique breeds: {len(unique_breeds)}\")\n",
        "print(f\"\")\n",
        "print(f\"Unique breeds: {(unique_breeds)}\")\n"
      ],
      "metadata": {
        "id": "Xl0mj0rOgyF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn single label into an array of booleans where everywhere there is a unique breeds but where it does equal it is true\n",
        "print(labels[0])\n",
        "labels[0] == unique_breeds"
      ],
      "metadata": {
        "id": "rfkAgHPqhKAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn every label into a boolean array\n",
        "#boolean_labels = [label == np.array(unique_breeds) for label in labels]\n",
        "boolean_labels = [label == unique_breeds for label in labels]\n",
        "boolean_labels[:2]\n"
      ],
      "metadata": {
        "id": "Ngt8kTEjhj4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(boolean_labels)"
      ],
      "metadata": {
        "id": "yxkrVCuUh_BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exaample Turning boolean array into integers\n",
        "print(labels[0]) # Original label\n",
        "print(np.where(unique_breeds==labels[0]))  #index where label occurs\n",
        "print(boolean_labels[0].argmax()) #index where label occurs in boolean array\n",
        "print(boolean_labels[0].astype(int)) # There will be a 1 where the sample label occurs"
      ],
      "metadata": {
        "id": "pMt5vZf1iBOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example Turning boolean array into integers\n",
        "var_index = 2\n",
        "VI = var_index\n",
        "print(labels[var_index]) # Original label\n",
        "print(np.where(unique_breeds==labels[var_index]))  #index where label occurs\n",
        "print(boolean_labels[var_index].argmax()) #index where label occurs in boolean array\n",
        "print(boolean_labels[var_index].astype(int)) # There will be a 1 where the sample label occurs"
      ],
      "metadata": {
        "id": "7fZXAtt0ij9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating our own validation set\n",
        "Since the dataset from kaggle doesn't come with a validation set so we will make our own\n",
        "\n",
        "We wills tart with ~1000 images and increase as needed"
      ],
      "metadata": {
        "id": "uln5xvxUiz82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up x and y variables\n",
        "X = filename\n",
        "y = boolean_labels"
      ],
      "metadata": {
        "id": "7n7cSJliixD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SEt number of images to use for experimenting\n",
        "NUM_IMAGES = 1000 #@param {type:\"slider\",min:1000,max:10000, step:1000}"
      ],
      "metadata": {
        "id": "aPx9iW5hjL6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's split data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Split them into training and validation of total size Num_images\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],y[:NUM_IMAGES],test_size=.2,random_state=42)\n",
        "\n",
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "metadata": {
        "id": "OtAwxNd7jlht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's have a loook at the training data\n",
        "X_train[:5], y_train[:2]"
      ],
      "metadata": {
        "id": "kVrg1IZ2kYAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Images\n",
        "\n",
        "Turning images into tensors (numerical representation)\n",
        "\n",
        "To preprocess images into tensors. We will write a function that does a few things:\n",
        "1. Take an image filapath as input\n",
        "2. Use Tensorflow to read the file and save it to a variable 'image'\n",
        "3. Turn our 'image' (a jpeg) into Tensors\n",
        "4. Resize the image to be the shape of (224,224)\n",
        "5. Return modified image\n",
        "\n",
        "Tutorials on\n",
        "[Tensorflow.org/tutorials ](https://Tensorflow.org/tutorials )\n",
        "\n",
        "How to load images [Tensorflow.org/tutorials/load_data/images ](https://Tensorflow.org/tutorials/load_data/images)"
      ],
      "metadata": {
        "id": "dPhjNPaKkk4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert image to NumPy array\n",
        "from matplotlib.pyplot import imread\n",
        "var_index = 42\n",
        "VI = var_index\n",
        "image = imread(filename[VI])\n",
        "print(f\"\" )\n",
        "print(f\"Image Shape: {(image.shape)}\")\n",
        "print(f\"Image Max: {(image.max())}\")\n",
        "print(f\"Image Min: {(image.min())}\")"
      ],
      "metadata": {
        "id": "ha5bzUTsk0og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "3zyuOOOMmSOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image[:2]"
      ],
      "metadata": {
        "id": "IosdDp5bm58o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can create a tensor from any image using\n",
        "tf.constant(image)[:2]"
      ],
      "metadata": {
        "id": "3SU66RowkhIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--\n",
        "## Input functions"
      ],
      "metadata": {
        "id": "Le-X0ABicBww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_title = Test\n",
        "image_type_num = 1\n",
        "image_type = \"other\"\n",
        "\n",
        "if image_type_num == 1:\n",
        "   # Maintains aspect ratio, fills gaps with black\n",
        "  image_type = \"pad\"\n",
        "elif image_type_num == 2:\n",
        "      # Forces image into square, can distort lesion shape\n",
        "    image_type =\"stretch\"\n",
        "\n",
        "elif image_type_num == 3:\n",
        "       # Resizes and crops to maintain aspect ratio without padding\n",
        "    image_type == \"crop\"\n",
        ""
      ],
      "metadata": {
        "id": "795igGkmcF3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Images pt 2\n",
        "Now we've seen what an image looks like as a Tensor, let's make a function to preprocess them\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1.   Take an image filapath as input\n",
        "2.   Use Tensorflow to read the file and save it to a variable 'image'\n",
        "3. Turn our 'image' (a jpeg) into Tensors\n",
        "4. Resize the image to be the shape of (224,224)\n",
        "5. Return modified image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "23KMmru2nHXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define image size (Using a single integer for height/width)\n",
        "IMG_SIZE = 224\n",
        "\n",
        "def process_image(image_path, image_type_num, img_size=IMG_SIZE):\n",
        "    \"\"\"\n",
        "    Takes an image file path and turns it into a Tensor.\n",
        "    Handles decoding, normalization, and resizing with padding.\n",
        "    \"\"\"\n",
        "\n",
        "    method = image_type_num\n",
        "    # 1. Read in the image file\n",
        "    raw_file = tf.io.read_file(image_path)\n",
        "\n",
        "    # 2. Decode the image.\n",
        "    # channels=3 ensures we get RGB even if the original is grayscale or RGBA.\n",
        "    image = tf.image.decode_jpeg(raw_file, channels=3)\n",
        "\n",
        "    # 3. Convert the color channel values from 0-255 to 0-1 (float32)\n",
        "    # This also acts as your normalization step\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "    # 4. Resize the image\n",
        "    # resize_with_pad adds black borders to maintain aspect ratio without stretching\n",
        "    image = tf.image.resize_with_pad(image,\n",
        "                                     target_height=img_size,\n",
        "                                     target_width=img_size)\n",
        "\n",
        "    if method == 1:\n",
        "        # Maintains aspect ratio, fills gaps with black\n",
        "        image = tf.image.resize_with_pad(image, img_size, img_size)\n",
        "\n",
        "    elif method == 2:\n",
        "        # Forces image into square, can distort lesion shape\n",
        "        image = tf.image.resize(image, [img_size, img_size])\n",
        "\n",
        "    elif method == 3:\n",
        "        # Resizes and crops to maintain aspect ratio without padding\n",
        "        image = tf.image.resize_with_crop_or_pad(image, img_size, img_size)\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "CEZ0J_U3nM4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Note: It is better to center the image instead of stretching or cropping arbitrarily"
      ],
      "metadata": {
        "id": "TyfqfrI1sHTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test what is happening at each stage\n",
        "#tensor = tf.io.read_file(filename[26])\n",
        "#tensor = tf.image.decode_jpeg(tensor,channels=3)\n",
        "#tensor =tf.image.convert_image_dtype(tensor, tf.float32)\n",
        "\n",
        "#tensor"
      ],
      "metadata": {
        "id": "MeiNAGUrnx2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning Data into Batches\n",
        "\n",
        "32 is default batchsize  \n",
        "\n",
        "Resources:\n",
        "Yann lecun\n",
        "Jeremy howard\n",
        "\n",
        "Why? If we try to calculate patterns in all 10000 images in one go they might not all fit into memory -- GPU is fast but still has limited memory. It might be more than 8 gb.\n",
        "\n",
        "You can manually adjust batch size if necessary\n",
        "\n",
        "To use TensorFlow effectively, we need our daa in the form of Tensor tuples which look like this\n",
        "'(image, label)'"
      ],
      "metadata": {
        "id": "-8NwnKaGr_w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple function to return a tuple (image, label)\n",
        "def get_image_label(image_path,label):\n",
        "  \"\"\" takes an image file path name and the associated label processes the image and returns a tuple of image, label \"\"\"\n",
        "  image = process_image(image_path)\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "0YMNWYvWsCPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#demo of the above\n",
        "#(process_image(X[42]),y[42])\n",
        "(process_image(X[42]),tf.constant(y[42]))"
      ],
      "metadata": {
        "id": "WNrLh3NltnfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turn Data into Batches 2\n",
        "\n",
        "Now we have a way to turn data into tuples of Tensors in the form (image,label) lets make a function to turn all of our data (X and y) into batches\n",
        "\n",
        "Read through documentation"
      ],
      "metadata": {
        "id": "p12BIPgpuNVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size 32 is a good start\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create a function to turn data into batches\n",
        "def create_data_batches(X,y=None, batch_size = BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image (X) and label (y) pairs.\n",
        "  Shuffles the data if its training data but doesn't shffle if it is validation data\n",
        "  Also accepts test data as input (no labels)\n",
        "  \"\"\"\n",
        "\n",
        "  # If the data is a test data set we don't have the labels\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # only filepaths no labels\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  # If the data is a valid dataset we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), #filepaths\n",
        "                                               tf.constant(y))) #labels\n",
        "\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    print(\"Creating training data batches...\")\n",
        "    # Turn filepaths and labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
        "\n",
        "    # Shuffling pathnames and labels...\n",
        "    data = data.shuffle(buffer_size=len(X))\n",
        "\n",
        "    #Create image label tuples which turns image path into preprocessed image\n",
        "    data = data.map(get_image_label)\n",
        "\n",
        "    #Turn training data into batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "    return data_batch"
      ],
      "metadata": {
        "id": "CMHjtxnWuV3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and data validation data batches\n",
        "\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "val_data = create_data_batches(X_val, y_val, valid_data=True)"
      ],
      "metadata": {
        "id": "-a737p1Fws5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the different attrivutes of data athes\n",
        "train_data.element_spec,val_data.element_spec"
      ],
      "metadata": {
        "id": "jeXcdlvvw4Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Our Data\n",
        "\n",
        "Our data is now in batches but it's abstract.\n",
        "\n",
        "Visualizations below"
      ],
      "metadata": {
        "id": "WUuIRpdQxMZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualizing data batches\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function for viewing images in a databatch\n",
        "def show_25_images (images,labels):\n",
        "  \"\"\"\n",
        "  Displays a plot of 25 images and their labels from data batch\n",
        "  \"\"\"\n",
        "  # Set up the figure\n",
        "  plt.figure(figsize=(10,10))\n",
        "  #Loop through 25 for displaying 25 images\n",
        "  for i in range(25):\n",
        "    ax = plt.subplot(5,5,i+1)\n",
        "    #Display an image\n",
        "    plt.imshow(images[i])\n",
        "    #Add the image label as the title\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    #Turn the grid lines off\n",
        "    #plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "YVUHJYf_xYcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "hw8XisD0yVIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "train_images, train_labels\n",
        "#show_25_images"
      ],
      "metadata": {
        "id": "sVshC3B2yKRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images), len(train_labels)"
      ],
      "metadata": {
        "id": "GkDSno8Rzysc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's visualize in our training batch\n",
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "show_25_images(train_images,train_labels)"
      ],
      "metadata": {
        "id": "oXPm3Lb3z7dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's visaulize our validation set\n",
        "val_images, val_labels = next(val_data.as_numpy_iterator())\n",
        "show_25_images(val_images,val_labels)"
      ],
      "metadata": {
        "id": "sfxqyhnB0wFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Our Inputs and Outputs\n",
        "\n",
        "Before building model there are lots of ways to build models\n",
        "\n",
        "We can take existing model\n",
        "Once we have baseline results\n",
        "Few things we need to define\n",
        "* The input shape (our images shape in the form of tensors) to our model\n",
        "* The output shape (image labels in the form of tensors) of our model\n",
        "* The URL of the model we want to use"
      ],
      "metadata": {
        "id": "j0cJNnKsxTEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a model -- input shape and output shape and URL of model\n",
        "IMG_SIZE"
      ],
      "metadata": {
        "id": "SBncIwS7xSpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup the input shape to the model\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE,3]\n",
        "\n",
        "# Setup output shape of our model\n",
        "OUTPUT_SHAPE = len(unique_breeds)\n",
        "\n",
        "# Setup model URL from Tensorflow Hub\n",
        "# MODEL_URL =\n"
      ],
      "metadata": {
        "id": "6gQlzAEtxK88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How machines learn and waht's going on behind the scenes\n",
        "\n",
        "How machines learn by GCP Grey on [Youtube](https://youtube.com/watch?v=R9OHn5ZF4Uo)\n",
        "\n",
        "Deep Learning series by 3Blue1Brown on [Youtube](https://youtube.com/watch?v=aircAruvnKk)"
      ],
      "metadata": {
        "id": "sovTmGXn18He"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Deep Learning Model\n",
        "TensorFlow Hub is a library for reusable machine learning modules\n",
        "Makes it very easy to get started.\n",
        "Model Zoo\n",
        "Papers with code\n",
        "Pytorch\n",
        "Pytorch at tesla\n",
        "\n",
        "Tensor flow hub\n",
        "-- Search by problem domain\n",
        "-- Similar to scikit\n",
        "-- Architecture can be neural network\n",
        "----Resent -- click on it -- Copy to clipboard -- download model create a resnet model\n",
        "Resnet 50 dialated backbones\n",
        "Resnet [https://youtu.be/oBklltKXtDE?t=173](https://youtu.be/oBklltKXtDE)\n",
        "\n",
        "The higher the number the better and logner to train\n",
        "\n",
        "Mobilenet v2\n",
        "- Requires Tensorflow 2\n"
      ],
      "metadata": {
        "id": "YIJ4lMDS4dHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup the input shape to the model\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE,3]\n",
        "\n",
        "# Setup output shape of our model\n",
        "OUTPUT_SHAPE = len(unique_breeds)\n",
        "\n",
        "# Setup model URL from Tensorflow Hub\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\"\n"
      ],
      "metadata": {
        "id": "a-T7WwCu48Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Deep Learning Model pt 2\n",
        "\n",
        "Use tensor flow keras api\n",
        "\n",
        "High level api for deep learning\n",
        "User friendly\n",
        "Easy to extend\n",
        "Modular\n",
        "\n",
        "Keep in mind difference between sequential and functional (currently using sequential)\n",
        "\n",
        "Neural layers --\n",
        "- input\n",
        "-- other layers to find patterns\n",
        "--- output\n",
        "\n",
        "\n",
        " Now we have inputs outputs and model -- let's put into kearas deep learning module\n",
        "  Creating a function which takes the input shape, output shape and model chosen as peramiters\n",
        "Define layers in Keras model in sequential -- do this first and then that\n",
        " Compiles model says what it should be evaluated and improved\n",
        " Builds the model - tels the model and the input shape\n",
        " Returns the model\n",
        "\n",
        "tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4  >>  m.build ([None,224,224,3])"
      ],
      "metadata": {
        "id": "190-sfBi6nsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function which builds a Keras model\n",
        "## Not currently working\n",
        "## compatible with old verison\n",
        "def create_model_v1(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE,model_url=MODEL_URL):\n",
        "  print(\"Building model with:\", MODEL_URL)\n",
        "\n",
        "  #Setup the model layers\n",
        "  model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
        "    tf.keras.layers.Dense(units=OUTPUT_SHAPE, activation=\"softmax\") # Layer 2 (output layer)\n",
        "  ])\n",
        "\n",
        "  # Complie the model\n",
        "  model.complie(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE)\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "9RSP6-G36mt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
        "    print(\"Building model with Keras Applications (MobileNetV2)\")\n",
        "\n",
        "    # 1. Setup the base model from Keras instead of TF Hub\n",
        "    # We use include_top=False to remove the 1000-class ImageNet head\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "\n",
        "    # 2. Freeze the base model layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # 3. Create your custom model\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(), # Flattens the base model output\n",
        "        tf.keras.layers.Dense(units=output_shape, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    # 4. Compile the model\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "NlZ4mYXhLs64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Currently working  compatible with old version\n",
        "import tensorflow as tf\n",
        "## v1 used this but want to get rid of it\n",
        "#import tensorflow_hub as hub\n",
        "import tf_keras  # Import the compatibility wrapper\n",
        "\n",
        "# Update your URL to the new Kaggle format (or use the redirect)\n",
        "# MODEL_URL = \"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/1\"\n",
        "\n",
        "def create_model_v1():\n",
        "    # Use tf_keras.Sequential instead of tf.keras.Sequential\n",
        "    model = tf_keras.Sequential([\n",
        "        hub.KerasLayer(MODEL_URL, input_shape=(224, 224, 3)),\n",
        "        tf_keras.layers.Dense(len(unique_breeds), activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=\"adam\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "J_J5_DZv-WPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compatible with this version\n",
        "import tensorflow as tf\n",
        "\n",
        "# Update your URL to the new Kaggle format (or use the redirect)\n",
        "MODEL_URL = \"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/1\"\n",
        "\n",
        "def create_model():\n",
        "    # 1. Use the built-in MobileNetV2 from tf.keras (No tf_keras or hub needed)\n",
        "    base_model = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(224, 224, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "\n",
        "    # 2. Freeze the base model\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # 3. Use tf.keras.Sequential (NOT tf_keras)\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(), # Flattens the 4D output to 1D\n",
        "        tf.keras.layers.Dense(len(unique_breeds), activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "VIcSLoJtMw2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Nlab2pjJ8Tfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Deep Learning Model 3\n",
        "\n",
        "Linear stack of layers -- Find patterns in input and create some output\n",
        "\n",
        "Why do they have two layers\n",
        "\n",
        "towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-84...\n",
        "\n",
        "Check out CNN\n",
        "\n",
        "Transfer learning -- a lot is re==predone\n",
        "\n",
        "Check out softmax -- each component will be interval 0,1\n",
        "Binary -- signoid\n",
        "\n",
        "Natural output is 1280 -- but we only need 120\n"
      ],
      "metadata": {
        "id": "tEd9Aa0t-6Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = np.ones(shape=(1,1, 1280))\n",
        "outputs\n"
      ],
      "metadata": {
        "id": "uJyTankH92lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizing our model\n",
        "\n",
        "### and editing\n",
        " Loss is height of the hill. Wants to get to 0.\n",
        " When it's learning the training set to compare image to a label\n",
        " Higher the loss the worse the prediction\n",
        " Higher we are -- goal is to get to bottom of the hill\n",
        "\n",
        " Adam is telling how to get to bottom of the hill - can see movemenet sand instructions\n",
        "\n",
        " Adam is an optimizer that works well on most models\n",
        " Metrics is how well doing at the bottom of the hill\n",
        " How well predicting label\n",
        "\n",
        " Search: How to choose a loss function in machine learning models\n",
        "\n",
        " ---- How to choose loss function\n",
        "\n",
        " Binary classification --- if something is one or another -- cat or dog\n",
        " Change activation: Sigmoid\n",
        " Loss function to binary cross entroppy\n",
        "\n",
        " Multiclass\n",
        " - Activation is softmax\n",
        " Loss- Categorical\n",
        "\n",
        " so loss - tf.keras.losses.CategoricalCrossentropy\n",
        "\n",
        " Metrics -- can use different metrics (search tf keras metrics)\n",
        "\n",
        " Use accuracy for classification\n",
        "\n",
        " Area under the curve, categorial, mean, precision, recall, etc.\n",
        "\n",
        "[ tensorflow.org/api_docs/python/tf/keras/metrics](https://tensorflow.org/api_docs/python/tf/keras/metrics)\n",
        "\n",
        "\n",
        "Building\n",
        "\n",
        "Just another way to say this is the input shape taking to the model -- taking from tensor flow hub -- if we want touse the layer set up a sequential model\n",
        "keras.Sequential\n",
        "m.build(none,224,224,3) -- size of images that mobilenet is trained on\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_oGFn1HVAJbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarizing Our Model\n",
        "\n",
        "Layer\n",
        "\n",
        "Non trainable lines up with param\n",
        "\n",
        "Dense with param number 120k that corresponds to dense layer\n",
        "\n",
        "Non-trainable params -- using mobile net v2\n",
        "\n",
        "There are specific patterns mobilenet has learned.\n",
        "\n",
        "What images did mobile net go through\n",
        "\n",
        "Search for imagenet -- weights were obtained by training on ILSVRC-2012-CLS imagenet\n",
        "imagenet organized according to wordnet hierarchy\n",
        "500 images per node\n",
        "\n",
        "Image net is large database of over 14 million images\n",
        "Patterns are what mobile net has learned by training on image net\n",
        "\n",
        "Transfer learning -- all patterns leraned each layer is a layer in the neural network\n",
        "\n",
        "-----\n",
        "\n",
        "5 1/2 Found\n",
        "\n",
        "Utilize patterns found in own pattern\n",
        "\n",
        "Find from scratch -- hours and lots of compute power -- utilize and train our own 120k parameters\n",
        "\n",
        "Dense layer\n",
        "\n",
        "Classify which dogbreed is in which photo\n",
        "\n",
        "Create callbacks\n",
        "\n",
        "Create a function"
      ],
      "metadata": {
        "id": "JSiFXRhVCfuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Our Model\n",
        "\n",
        "Checked out what summarizing means\n",
        "\n",
        "Call backs\n",
        "\n",
        "### Creating callbascks\n",
        "\n",
        "Callbacks are helper functions a model can use during training to do such things as save its progress, check its progress to stop training early if model stops improving\n",
        "\n",
        "Why should we implement\n",
        "\n",
        "tensorflow.keras.model callbacks -- check documentation\n",
        "tensorflow.org/guide/keras/custom_callbacks\n",
        "\n",
        "Can train model for up to a week at a time.\n",
        "\n",
        "Want to know how its going and what it's doing.\n",
        "\n",
        "Want to stop early before it overfits.\n",
        "\n",
        "Will do callbacks in action\n",
        "\n",
        "Create two callbacks\n",
        "\n",
        "One for Tensorboard which helps track our model progress and another for early stopping which prevents our model from training for too long\n",
        "\n",
        "\n",
        "### TensorBoard callback\n",
        "tensorflow.org/\n",
        "\n",
        "#### To set up Tensorboard callback we need 3 things\n",
        "1. Load the Tensorboard notebook extension\n",
        "2. Create a Tensorboard callback which is able to save logs to a directory -- how it's doing during trianng and pass to model's fit() function\n",
        "3. Visualize our models training logs with the '%tensorboard machic function' -- do this after model training  "
      ],
      "metadata": {
        "id": "RSIqASSWDmXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load TensorBoard notebook extension\n",
        "%load_ext tensorboard\n"
      ],
      "metadata": {
        "id": "J_PiSsVmDrCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback --start timelog\n",
        "import datetime\n",
        "def create_tensorboard_callback():\n",
        "  # Fix the typo: 'dateime' -> 'datetime'\n",
        "  logdir = os.path.join(\"/content/drive/MyDrive/ZeroToMastery/DogVision/logs\",\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "  # Ensure you are using tf.keras specifically to avoid attribute errors\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "metadata": {
        "id": "4fnzF0xWEh3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preventing Overfitting\n",
        "\n",
        "Create an early stopping callback\n",
        "\n",
        "Tensorflow kears early stopping callback\n",
        "\n",
        "Early stopping helps our model from overfitting by stopping trainng if a certain evaluation metric stops improving."
      ],
      "metadata": {
        "id": "R8z2U-f-GMXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create aerly stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=3)\n",
        "\n",
        "#Patience 3 is the number of epochs with the value"
      ],
      "metadata": {
        "id": "x4nGcfnTG0yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training your deep neural network\n",
        "### On a subset of data -- 1000 images\n",
        "\n",
        "Why? To make sure everything is working\n",
        "\n",
        "One more variable to define -- number of epochs -- how many passes of data we'd like data to do\n",
        "\n",
        "Equivalent to model finding patterns in\n",
        "\n",
        "As it learns patterns -- will guess --\n",
        "\n",
        "Tell model how it will guess with each epoch\n",
        "\n",
        "Tell how it is going on accuracy\n",
        "\n",
        "Watching how well performing"
      ],
      "metadata": {
        "id": "nKxa6w13HTRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}"
      ],
      "metadata": {
        "id": "2U_mVnP5HKcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Double check we are using a GPU\n",
        "print(\"GPU\",\"available? YESSSSS \" if tf.config.list_physical_devices(\"GPU\") else \"not available :-(\")"
      ],
      "metadata": {
        "id": "lZ0zfEkxIGLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ------\n",
        "Let's create a function which trains a model\n",
        " * create a model using 'create model\n",
        " * Set up a tensorBoard Callback using create_tensor_board_callback()\n",
        "\n",
        "* Call the 'fit()' funciton on model passing the training data and validation data\n",
        "number of epocs tho train for (NUM_EPOCHS)\n",
        "and the callback swhich are the helper functions\n",
        "* Return the model"
      ],
      "metadata": {
        "id": "ju_YnwX4IYT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a function to train and return a trained model\n",
        "def train_model():\n",
        "  \"\"\"\n",
        "  Trains a given model and returns the trained version\n",
        "  \"\"\"\n",
        "  # Create a model\n",
        "  model = create_model()\n",
        "\n",
        "  # Create new TensorBoard session everytime we train a model\n",
        "  tensorboard = create_tensorboard_callback()\n",
        "\n",
        "  # Fit the model to the data passing it the callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            validation_data=val_data,\n",
        "            validation_freq = 1,\n",
        "            callbacks = [tensorboard,early_stopping])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "LUf9VDcPIrJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIt the model to the data\n",
        "model = train_model()"
      ],
      "metadata": {
        "id": "3wgZsNf0JdTY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1BCbvMd8Xsa3zoXMye5tFRFXKVzWiBTP1",
      "authorship_tag": "ABX9TyP71HPC3qLh9i0Zau46tVtj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}